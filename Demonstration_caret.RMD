---
title: "Demonstration of Caret for Machine Learning"
author: "JAS"
date: " "
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Overview of the Caret Package

The caret package (Classification And REgression Training) contains a number of functions to streamline the process for creating analytic pipelines for prediction. It calls to other libraries to run algorithms, but provides a seamless and uniform interface for working with different algorithms. We will use it often in this class, so I"m going to give a quick overview now.

Primary functionalities of caret include:

* pre-processing
* data splitting
* feature selection
* model tuning using resampling
* variable importance estimation

***

Helpful resources using caret:

Max Kuhn's explainer of the caret package
https://topepo.github.io/caret/model-training-and-tuning.html

Kuhn M. Building predictive models in R using the caret package. Journal of Statistical Software 2008;28(5) doi: 10.18637/jss.v028.i05

Webinar, given by Max Kuhn, available on YouTube (~1 hour): https://www.youtube.com/watch?v=7Jbb2ItbTC4


### Some useful functions for pre-processing
```{r dataclean}
library(tidyverse)
library(caret)
library(stats)

bc.data<-read.csv("C:/Users/js5406/OneDrive - cumc.columbia.edu/EPIC Course/breast-cancer-wisconsin.data.txt", header=FALSE)

var.names<-c("id", "clump_thickness", "uniformity_csize", "uniformity_cshape", "marg_adhesion", "single_ecell_size", "bare_nuclei", "b_chromatin", "normal_nucleoli", "mitoses", "outcome")

colnames(bc.data)<-var.names
str(bc.data)

bc.data[bc.data=="?"]<-NA
bc.data$bare_nuclei<-as.numeric(bc.data$bare_nuclei)
bc.data$id<-as.character(bc.data$id)

bc.data$outcome<-as.factor(bc.data$outcome)
levels(bc.data$outcome)<-c("Benign", "Malignant")
str(bc.data)

summary(bc.data)

missmap(bc.data, main = "Missing values vs observed")

#Remove missings
bc.data<-na.omit(bc.data)

#Remove duplicate IDs
bc.data=bc.data %>% distinct(id, .keep_all=TRUE)
```


```{r preprocess}
#Finding correlated predictors
bc.data.numeric<- bc.data %>% dplyr::select(where(is.numeric))

correlations<-cor(bc.data.numeric, use="complete.obs")
high.correlations<-findCorrelation(correlations, cutoff=0.9)

#Remove highly correlated features
new.data.low.corr<-bc.data.numeric[,-high.correlations]


#Centering and Scaling
set.up.preprocess<-preProcess(bc.data.numeric, method=c("center", "scale"))
#Output pre-processed values
transformed.vals<-predict(set.up.preprocess, bc.data.numeric)

set.seed(111)
#Strip off ID var
bc.data$id<-NULL

#Creating balanced partitions in the data
train.index<-createDataPartition(bc.data$outcome, p=0.7, list=FALSE)

bc.train<-bc.data[train.index,]
bc.test<-bc.data[-train.index,]


#Construct k-folds in your data
train.folds<-createFolds(bc.data$outcome, k=10, list=FALSE)

```

### Model Training and Tuning


```{r models}

names(getModelInfo())

modelLookup("rpart")
modelLookup("adaboost")

#Train Function: used for tuning of hyperparameters and choosing "optimal" model

#Use trainControl Function to set method, default is bootstrapping

#Perform 3-fold cross-validation
control.settings<-trainControl(method="cv", number=3)

#Perform repeated 10-fold cross-validation
control.settings.b<-trainControl(method="repeatedcv", number=10, repeats=10)

#Add into train function
set.seed(111)
logit <- train(
 outcome ~., data = bc.train, method = "glm", family="binomial",
  trControl = control.settings)

logit
logit$results
logit$resample
logit$finalModel

```

### Model Evaluation

```{r}
#Obtain confusion matrix
test.outcome<-predict(logit, bc.test)
confusionMatrix(test.outcome, bc.test$outcome, positive="Malignant")

#Obtain predicted probabilities
test.outcome.probs<-predict(logit, bc.test, type="prob")

testProbs.rmodel <- data.frame(obs = bc.test$outcome,
                        pred.logit=test.outcome.probs[,2])

#Create calibration plot
calPlotData.rmodel<-calibration(obs ~ pred.logit, data = testProbs.rmodel, class="Malignant", cuts=5)
xyplot(calPlotData.rmodel, auto.key = list(columns = 2))

plot(test.outcome.probs[,2])

#What do I do if my outcome is continuous???

postResample(pred=..., obs=....)
```

